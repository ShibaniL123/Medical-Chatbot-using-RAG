{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "KibP9c_yHPEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "rCDXNUoaP-Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02f64ce-6fe0-4314-e827-c09f75f7e82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.45)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.3)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JyeXV0fNXJB"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  pinecone-client==2.2.4 \\\n",
        "  langchain==0.0.321 \\\n",
        "  datasets==2.14.6 \\\n",
        "  openai==0.27.4 \\\n",
        "  tiktoken==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "bM0ZbsgNNbYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed29b6b-16cf-4f05-8b11-69d6d03b9461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.17.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.9.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.7)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.9.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.9.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.36.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_CSE_ID\"] = \"xxx\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"xxx\"\n",
        "my_key = \"xxx\""
      ],
      "metadata": {
        "id": "mOR9BYI7MEN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "import pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "import logging\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import openai\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "w98jPyZ7MHd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374d06d4-028d-4c27-dc25-232b9795463f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key = \"xxx\",\n",
        "    environment= \"xxx\"\n",
        ")"
      ],
      "metadata": {
        "id": "Jd3BUH3bONhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = 'med277-medquad'\n",
        "index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "C1qau-9NOXW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "8sEI7KmtOawI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\", openai_api_key=my_key, disallowed_special=()\n",
        ")"
      ],
      "metadata": {
        "id": "UH749GbSOcro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = \"question\"\n",
        "vectorstore = Pinecone(index, embed.embed_query, text_field)"
      ],
      "metadata": {
        "id": "6xo_Lfb_OgH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb085c9-137e-44ae-cfc7-bc62009f82cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, openai_api_key=my_key)"
      ],
      "metadata": {
        "id": "b15ihtu2OjLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a5b12f-4418-4018-c735-a5de1aec581d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<class 'openai.api_resources.chat_completion.ChatCompletion'> temperature=0.0 openai_api_key='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' openai_api_base='' openai_organization='' openai_proxy=''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectorstore.as_retriever(), llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "-20tr7ThOobL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "Mx90QWmlOuTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")"
      ],
      "metadata": {
        "id": "8CSBcrwDOxsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebc0957-e473-4b2c-8463-be4e128130e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_prompt(query: str):\n",
        "    # get top 3 results from knowledge base\n",
        "    results = vectorstore.similarity_search(query, k=3)\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided. If the question cannot be answered using the information\n",
        "    provided say \"I don't know\"\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ],
      "metadata": {
        "id": "SkH5yhPUOv78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_prompt_google(query: str):\n",
        "    search = GoogleSearchAPIWrapper()\n",
        "\n",
        "    def top10_results(query):\n",
        "        return search.results(query, 10)\n",
        "\n",
        "    tool = Tool(\n",
        "        name=\"Google Search Snippets\",\n",
        "        description=\"Search Google for recent results.\",\n",
        "        func=top10_results,\n",
        "    )\n",
        "    source_knowledge = tool.run(query)\n",
        "\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided. Cite the sources which you used to answer the question.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ],
      "metadata": {
        "id": "xweqt_vKLr8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.machinery import SourcelessFileLoader\n",
        "def augment_prompt_chatbot(query, history):\n",
        "    search = GoogleSearchAPIWrapper()\n",
        "\n",
        "    def top5_results(query):\n",
        "        return search.results(query, 5)\n",
        "\n",
        "    tool = Tool(\n",
        "        name=\"Google Search Snippets\",\n",
        "        description=\"Search Google for recent results.\",\n",
        "        func=top5_results,\n",
        "    )\n",
        "    source_knowledge = tool.run(query)\n",
        "    prompt = ''\n",
        "    if len(history)>0:\n",
        "      prompt = \"\\n\".join([f\"User questions: {message[0]}\"\n",
        "                           for message in history[-3:]])\n",
        "\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided, and the history of the chat. Cite the sources which you used to answer the question.\n",
        "\n",
        "    Chat History:\n",
        "    {prompt}\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ],
      "metadata": {
        "id": "xUFvlGC1eZu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "\n",
        "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]"
      ],
      "metadata": {
        "id": "JaY4Dvg7O8iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unified_process(input_data):\n",
        "    query = transcribe(input_data)\n",
        "    print(\"query transcribed\",query)\n",
        "    llm = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "    )\n",
        "    augmented_prompt = augment_prompt(query)\n",
        "    return llm(augmented_prompt)"
      ],
      "metadata": {
        "id": "qjkicI3FO5WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unified_process_googleAPI(input_data):\n",
        "    query = transcribe(input_data)\n",
        "    print(\"query transcribed\",query)\n",
        "    llm = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "    )\n",
        "    augmented_prompt = augment_prompt_google(query)\n",
        "    return llm(augmented_prompt)"
      ],
      "metadata": {
        "id": "1ARj37qkZkcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unified_process_chatbot(message, history):\n",
        "  print(\"message \",message)\n",
        "  augmented_prompt = augment_prompt_chatbot(message,history)\n",
        "  llm2 = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "  )\n",
        "  return llm2(augmented_prompt)"
      ],
      "metadata": {
        "id": "OKgamL30byWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "co = cohere.Client('xxx')\n",
        "chat_history = []\n",
        "def unified_process_cohere(input_data):\n",
        "    query = transcribe(input_data, transcriber)\n",
        "    response = co.chat(message = query,\n",
        "        connectors=[{\"id\": \"web-search\"}],\n",
        "        preamble_override='You are a medical expert here to help answer questions that people may have',\n",
        "        stream = True,\n",
        "        chat_history = chat_history)\n",
        "\n",
        "    urls = [doc['url'] for doc in response.documents]\n",
        "    urls_string = '\\n'.join(urls)\n",
        "\n",
        "    return response.text + f\"\\n Here are my sources \\n - {urls_string}\""
      ],
      "metadata": {
        "id": "2aoxXm3YQfOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=1, openai_api_key=my_key)\n",
        "my_key = \"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\"\n",
        "chat = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        ")\n",
        "a1 = augment_prompt_google(\"hi\")\n",
        "chat(a1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hWX838tf1NXA",
        "outputId": "c8eb3b69-02ea-4942-f0dd-db7f91ce0bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n    Sources used:\\n    1. Merriam-Webster Dictionary - https://www.merriam-webster.com/dictionary/hi\\n    2. Hawaii.gov - https://portal.ehawaii.gov/\\n    3. YouTube - https://www.youtube.com/watch?v=ceKMnyMYIMo\\n    4. hi.com - https://hi.com/\\n    5. Dictionary.com - https://www.dictionary.com/browse/hi\\n    6. Instagram - https://www.instagram.com/hilo_ofc/?hl=en\\n    7. Hawaii Judiciary - https://www.courts.state.hi.us/\\n    8. Honolulu.gov - https://www.honolulu.gov/\\n    9. Twitter - https://twitter.com/CovertShores\\n    10. Hawaii State Legislature - https://www.capitol.hawaii.gov/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tabbed interface\n",
        "stt_demo = gr.Interface(\n",
        "    unified_process,\n",
        "    gr.Audio(sources=[\"microphone\"]),\n",
        "    \"text\",\n",
        "    title = \"RAG over MedQuAD dataset\"\n",
        ")\n",
        "\n",
        "stt_demo_google = gr.Interface(\n",
        "    unified_process_googleAPI,\n",
        "    gr.Audio(sources=[\"microphone\"]),\n",
        "    \"text\",\n",
        "    title = \"RAG using Google Search API\"\n",
        ")\n",
        "\n",
        "stt_demo_cohere = gr.Interface(\n",
        "    unified_process,\n",
        "    inputs = gr.Audio(sources=[\"microphone\"]),\n",
        "    outputs = \"text\",\n",
        "    title = \"Medical Q&A using Cohere\"\n",
        ")\n",
        "\n",
        "chatbot_demo = gr.ChatInterface(fn=unified_process_chatbot, title = 'Medical Q&A chatbot')\n",
        "\n",
        "\n",
        "demo = gr.TabbedInterface([stt_demo, stt_demo_google, chatbot_demo, stt_demo_cohere], [\"Speech-to-text RAG-Vector DB\",\"Speech-to-text RAG-Google\", \"Medical Q&A Chatbot\", \"Cohere\"])\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "H8iHBC18YNfn",
        "outputId": "042ccafd-de60-4e80-b8ef-c967ec6a5f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d90a816ce8d1092e3b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d90a816ce8d1092e3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNOj7ntkLsQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}