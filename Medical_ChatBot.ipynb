{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KibP9c_yHPEf"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCDXNUoaP-Jp",
        "outputId": "c02f64ce-6fe0-4314-e827-c09f75f7e82f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.45)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.3)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JyeXV0fNXJB"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  pinecone-client==2.2.4 \\\n",
        "  langchain==0.0.321 \\\n",
        "  datasets==2.14.6 \\\n",
        "  openai==0.27.4 \\\n",
        "  tiktoken==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM0ZbsgNNbYD",
        "outputId": "3ed29b6b-16cf-4f05-8b11-69d6d03b9461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.17.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.9.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.7)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.9.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.9.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.36.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOR9BYI7MEN_"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_CSE_ID\"] = \"xxx\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"xxx\"\n",
        "my_key = \"xxx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w98jPyZ7MHd3",
        "outputId": "374d06d4-028d-4c27-dc25-232b9795463f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "import pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "import logging\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import openai\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd3BUH3bONhH"
      },
      "outputs": [],
      "source": [
        "pinecone.init(\n",
        "    api_key = \"xxx\",\n",
        "    environment= \"xxx\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1qau-9NOXW2"
      },
      "outputs": [],
      "source": [
        "index_name = 'med277-medquad'\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sEI7KmtOawI"
      },
      "outputs": [],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH749GbSOcro"
      },
      "outputs": [],
      "source": [
        "embed = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\", openai_api_key=my_key, disallowed_special=()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xo_Lfb_OgH9",
        "outputId": "0fb085c9-137e-44ae-cfc7-bc62009f82cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "text_field = \"question\"\n",
        "vectorstore = Pinecone(index, embed.embed_query, text_field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b15ihtu2OjLF",
        "outputId": "c4a5b12f-4418-4018-c735-a5de1aec581d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<class 'openai.api_resources.chat_completion.ChatCompletion'> temperature=0.0 openai_api_key='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' openai_api_base='' openai_organization='' openai_proxy=''\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(temperature=0, openai_api_key=my_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Code to insert data in vector DB\n",
        "# import time\n",
        "\n",
        "# index_name = 'med277-medquad'\n",
        "\n",
        "# if index_name not in pinecone.list_indexes():\n",
        "#     pinecone.create_index(\n",
        "#         index_name,\n",
        "#         dimension=1536,\n",
        "#         metric='cosine'\n",
        "#     )\n",
        "#     # wait for index to finish initialization\n",
        "#     while not pinecone.describe_index(index_name).status['ready']:\n",
        "#         time.sleep(1)\n",
        "\n",
        "# index = pinecone.Index(index_name)\n",
        "# from tqdm.auto import tqdm  # for progress bar\n",
        "\n",
        "# batch_size = 100\n",
        "# data = df\n",
        "# for i in tqdm(range(0, len(data), batch_size)):\n",
        "#     i_end = min(len(data), i+batch_size)\n",
        "#     # get batch of data\n",
        "#     batch = data.iloc[i:i_end]\n",
        "#     # generate unique ids for each chunk\n",
        "#     ids = [str(i) for i, _ in batch.iterrows()]\n",
        "#     # print(ids)\n",
        "#    # get text to embed\n",
        "#     question = [x['Question'] for _, x in batch.iterrows()]\n",
        "#     # answer = [x['Answer'] for _, x in batch.iterrows()]\n",
        "#     # qtype = [x['qtype'] for _, x in batch.iterrows()]\n",
        "#     # embed text\n",
        "#     embeds = embed_model.embed_documents(question)\n",
        "#     # get metadata to store in Pinecone\n",
        "#     metadata = [\n",
        "#         {'question': x['Question'],\n",
        "#          'qtype': x['qtype'],\n",
        "#          'answer': x['Answer']} for i, x in batch.iterrows()\n",
        "#     ]\n",
        "#     # add to Pinecone\n",
        "#     index.upsert(vectors=zip(ids, embeds, metadata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-20tr7ThOobL"
      },
      "outputs": [],
      "source": [
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectorstore.as_retriever(), llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx90QWmlOuTT"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CSBcrwDOxsr",
        "outputId": "6ebc0957-e473-4b2c-8463-be4e128130e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkH5yhPUOv78"
      },
      "outputs": [],
      "source": [
        "def augment_prompt(query: str):\n",
        "    # get top 3 results from knowledge base\n",
        "    results = vectorstore.similarity_search(query, k=3)\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided. If the question cannot be answered using the information\n",
        "    provided say \"I don't know\"\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xweqt_vKLr8p"
      },
      "outputs": [],
      "source": [
        "def augment_prompt_google(query: str):\n",
        "    search = GoogleSearchAPIWrapper()\n",
        "\n",
        "    def top10_results(query):\n",
        "        return search.results(query, 10)\n",
        "\n",
        "    tool = Tool(\n",
        "        name=\"Google Search Snippets\",\n",
        "        description=\"Search Google for recent results.\",\n",
        "        func=top10_results,\n",
        "    )\n",
        "    source_knowledge = tool.run(query)\n",
        "\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided. Cite the sources which you used to answer the question.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUFvlGC1eZu2"
      },
      "outputs": [],
      "source": [
        "from importlib.machinery import SourcelessFileLoader\n",
        "def augment_prompt_chatbot(query, history):\n",
        "    search = GoogleSearchAPIWrapper()\n",
        "\n",
        "    def top5_results(query):\n",
        "        return search.results(query, 5)\n",
        "\n",
        "    tool = Tool(\n",
        "        name=\"Google Search Snippets\",\n",
        "        description=\"Search Google for recent results.\",\n",
        "        func=top5_results,\n",
        "    )\n",
        "    source_knowledge = tool.run(query)\n",
        "    prompt = ''\n",
        "    if len(history)>0:\n",
        "      prompt = \"\\n\".join([f\"User questions: {message[0]}\"\n",
        "                           for message in history[-3:]])\n",
        "\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided, and the history of the chat. Cite the sources which you used to answer the question.\n",
        "\n",
        "    Chat History:\n",
        "    {prompt}\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaY4Dvg7O8iM"
      },
      "outputs": [],
      "source": [
        "def transcribe(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "\n",
        "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjkicI3FO5WV"
      },
      "outputs": [],
      "source": [
        "def unified_process(input_data):\n",
        "    query = transcribe(input_data)\n",
        "    print(\"query transcribed\",query)\n",
        "    llm = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "    )\n",
        "    augmented_prompt = augment_prompt(query)\n",
        "    return llm(augmented_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ARj37qkZkcN"
      },
      "outputs": [],
      "source": [
        "def unified_process_googleAPI(input_data):\n",
        "    query = transcribe(input_data)\n",
        "    print(\"query transcribed\",query)\n",
        "    llm = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "    )\n",
        "    augmented_prompt = augment_prompt_google(query)\n",
        "    return llm(augmented_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKgamL30byWa"
      },
      "outputs": [],
      "source": [
        "def unified_process_chatbot(message, history):\n",
        "  print(\"message \",message)\n",
        "  augmented_prompt = augment_prompt_chatbot(message,history)\n",
        "  llm2 = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        "  )\n",
        "  return llm2(augmented_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aoxXm3YQfOV"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "co = cohere.Client('xxx')\n",
        "chat_history = []\n",
        "def unified_process_cohere(input_data):\n",
        "    query = transcribe(input_data, transcriber)\n",
        "    response = co.chat(message = query,\n",
        "        connectors=[{\"id\": \"web-search\"}],\n",
        "        preamble_override='You are a medical expert here to help answer questions that people may have',\n",
        "        stream = True,\n",
        "        chat_history = chat_history)\n",
        "\n",
        "    urls = [doc['url'] for doc in response.documents]\n",
        "    urls_string = '\\n'.join(urls)\n",
        "\n",
        "    return response.text + f\"\\n Here are my sources \\n - {urls_string}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hWX838tf1NXA",
        "outputId": "c8eb3b69-02ea-4942-f0dd-db7f91ce0bc8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n    Sources used:\\n    1. Merriam-Webster Dictionary - https://www.merriam-webster.com/dictionary/hi\\n    2. Hawaii.gov - https://portal.ehawaii.gov/\\n    3. YouTube - https://www.youtube.com/watch?v=ceKMnyMYIMo\\n    4. hi.com - https://hi.com/\\n    5. Dictionary.com - https://www.dictionary.com/browse/hi\\n    6. Instagram - https://www.instagram.com/hilo_ofc/?hl=en\\n    7. Hawaii Judiciary - https://www.courts.state.hi.us/\\n    8. Honolulu.gov - https://www.honolulu.gov/\\n    9. Twitter - https://twitter.com/CovertShores\\n    10. Hawaii State Legislature - https://www.capitol.hawaii.gov/'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = OpenAI(temperature=1, openai_api_key=my_key)\n",
        "my_key = \"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\"\n",
        "chat = OpenAI(\n",
        "    openai_api_key=my_key,\n",
        "    model='gpt-3.5-turbo-instruct'\n",
        ")\n",
        "a1 = augment_prompt_google(\"hi\")\n",
        "chat(a1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "H8iHBC18YNfn",
        "outputId": "042ccafd-de60-4e80-b8ef-c967ec6a5f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d90a816ce8d1092e3b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d90a816ce8d1092e3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#tabbed interface\n",
        "stt_demo = gr.Interface(\n",
        "    unified_process,\n",
        "    gr.Audio(sources=[\"microphone\"]),\n",
        "    \"text\",\n",
        "    title = \"RAG over MedQuAD dataset\"\n",
        ")\n",
        "\n",
        "stt_demo_google = gr.Interface(\n",
        "    unified_process_googleAPI,\n",
        "    gr.Audio(sources=[\"microphone\"]),\n",
        "    \"text\",\n",
        "    title = \"RAG using Google Search API\"\n",
        ")\n",
        "\n",
        "stt_demo_cohere = gr.Interface(\n",
        "    unified_process,\n",
        "    inputs = gr.Audio(sources=[\"microphone\"]),\n",
        "    outputs = \"text\",\n",
        "    title = \"Medical Q&A using Cohere\"\n",
        ")\n",
        "\n",
        "chatbot_demo = gr.ChatInterface(fn=unified_process_chatbot, title = 'Medical Q&A chatbot')\n",
        "\n",
        "\n",
        "demo = gr.TabbedInterface([stt_demo, stt_demo_google, chatbot_demo, stt_demo_cohere], [\"Speech-to-text RAG-Vector DB\",\"Speech-to-text RAG-Google\", \"Medical Q&A Chatbot\", \"Cohere\"])\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNOj7ntkLsQX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
